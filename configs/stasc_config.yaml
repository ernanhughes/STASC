
# Model Configuration
model_path: "Qwen/Qwen2.5-0.5B-Instruct" #'microsoft/Phi-3-mini-4k-instruct' # "Qwen/Qwen2.5-1.5B-Instruct"
cache_dir: "/home/data/v.moskvoretskii/cache/"
gpu_memory_utilization: 0.95        # GPU memory utilization (0.0 to 1.0)
enforce_eager: False               # Whether to enforce eager execution
max_model_len: 2048                # Maximum model length
random_seed: 42

# Dataset Configuration
task_type: "qa"
data_path: "data/datasets/s_nq"
id_col: "question_id"                        # Unique identifier column in the dataset. "question_id" for QA, "problem" for "unique_id"
question_col: "question_text"            # Column containing the question text. "question_text" for QA, "problem" for math500
gold_col: "reference"                   # Reference/GT answer column. "reference" for QA, "answer" for math500

num_star_iterations: 2
run_name: "test_refactor"
initial_answer_with_new_model: True
only_better_correction: True
train_from_initial_model: True

# Reward Function
evaluator_mode: 'final'   # "default" will input all answer in reward func, "final" only string after "evaluator_answer_marker"
evaluator_function: 'in_acc' # metric function to use, in_acc, f1, em for QA, "math_acc" for math500. math500 always has "final" evaluation mode
evaluator_answer_marker: 'Final Answer:' # the key word to find answer after. truncates answer untils this phrase. Case insensetive

# Generation Configuration
few_shot_dir: "few_shots"            # Directory containing few-shot JSON files
number_output_initial_generations: 1         
number_output_corrections: 1

# Sampling Parameters
temperature: 0.8                    # Sampling temperature
top_p: 0.9                           # Top-p (nucleus) sampling
max_tokens: 512                      # Maximum number of tokens to generate
